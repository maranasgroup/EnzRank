{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63572bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 21:23:45.873433: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 21:23:46.083324: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-29 21:24:00.309560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 21:24:00.309733: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 21:24:00.309745: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import rdChemReactions as Reactions\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import pad_sequences\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import argparse\n",
    "import h5py\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06cff18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_rdic = ['A', 'I', 'L', 'V', 'F', 'W', 'Y', 'N', 'C', 'Q', 'M',\n",
    "    'S', 'T', 'D', 'E', 'R', 'H', 'K', 'G', 'P', 'O', 'U', 'X', 'B', 'Z']\n",
    "seq_dic = {w: i+1 for i, w in enumerate(seq_rdic)}\n",
    "\n",
    "\n",
    "def encodeSeq(seq, seq_dic):\n",
    "    if pd.isnull(seq):\n",
    "        return [0]\n",
    "    else:\n",
    "        return [seq_dic[aa] for aa in seq]\n",
    "\n",
    "\n",
    "def load_modelfile(model_string):\n",
    "\tloaded_model = tf.keras.models.load_model(model_string)\n",
    "\treturn loaded_model\n",
    "\n",
    "\n",
    "def prot_feature_gen_from_str_input(prot_input_str, prot_len=2500):\n",
    "    Prot_ID = prot_input_str.split(':')[0]\n",
    "    Prot_seq = prot_input_str.split(':')[1]\n",
    "    prot_dataframe = pd.DataFrame(\n",
    "        {'Protein_ID': Prot_ID, 'Sequence': Prot_seq}, index=[0])\n",
    "    prot_dataframe.set_index('Protein_ID')\n",
    "\n",
    "    prot_dataframe[\"encoded_sequence\"] = prot_dataframe.Sequence.map(\n",
    "        lambda a: encodeSeq(a, seq_dic))\n",
    "    prot_feature = pad_sequences(\n",
    "        prot_dataframe[\"encoded_sequence\"].values, prot_len)\n",
    "\n",
    "    return prot_feature, Prot_ID\n",
    "\n",
    "\n",
    "def mol_feature_gen_from_str_input(mol_str):\n",
    "\ttry:\n",
    "\t\tmol_ID = mol_str.split(':')[0]\n",
    "\t\tmol_smiles = mol_str.split(':')[1]\n",
    "\t\tmol = Chem.MolFromSmiles(mol_smiles)\n",
    "\t\tfp1 = AllChem.GetMorganFingerprintAsBitVect(\n",
    "\t\t    mol, useChirality=True, radius=2, nBits=2048)\n",
    "\t\tfp_list = list(np.array(fp1).astype(float))\n",
    "\t\tfp_str = list(map(str, fp_list))\n",
    "\t\tmol_fp = '\\t'.join(fp_str)\n",
    "\n",
    "\t\tmol_dict = {}\n",
    "\t\tmol_dict['Compound_ID'] = mol_ID\n",
    "\t\tmol_dict['Smiles'] = mol_smiles\n",
    "\t\tmol_dict['morgan_fp_r2'] = mol_fp\n",
    "\n",
    "\t\tmol_info_df = pd.DataFrame(mol_dict, index=[0])\n",
    "\t\tmol_info_df = mol_info_df.set_index('Compound_ID')\n",
    "\n",
    "\t\tfinal_return = mol_info_df\n",
    "\t\tfinal_id = mol_ID\n",
    "\n",
    "\texcept Exception as error:\n",
    "\t\tprint('Something wrong with molecule input string...' + repr(error))\n",
    "\n",
    "\treturn final_return, final_id\n",
    "\n",
    "\n",
    "def act_df_gen_mol_feature(mol_id, prot_id):\n",
    "\tact_df = pd.DataFrame(\n",
    "\t    {'Protein_ID': prot_id, 'Compound_ID': mol_id}, index=[0])\n",
    "\n",
    "\treturn act_df\n",
    "\n",
    "\n",
    "def compound_feature_gen_df_input(act_df, comp_df, comp_len=2048, comp_vec='morgan_fp_r2'):\n",
    "\tact_df = pd.merge(act_df, comp_df, left_on='Compound_ID', right_index=True)\n",
    "\tcomp_feature = np.stack(act_df[comp_vec].map(lambda fp: fp.split(\"\\t\")))\n",
    "\tcomp_feature = comp_feature.astype('float')\n",
    "\treturn comp_feature\n",
    "\n",
    "\n",
    "def model_prediction(compound_feature, enz_feature, model):\n",
    "    prediction_vals = model.predict([compound_feature, enz_feature])\n",
    "\n",
    "    return prediction_vals[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a2162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_file = pd.read_csv('../CNN_data/test_CYP450/test_cyp450_act.csv', usecols=[1,2,3])\n",
    "comp_file = pd.read_csv('../CNN_data/test_CYP450/test_compound_CYP.csv', usecols=[1,2])\n",
    "prot_file = pd.read_csv('../CNN_data/test_CYP450/test_prot_cyp_new.csv', usecols=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab840a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_file_pid = prot_file['Protein_ID'].tolist()\n",
    "prot_file_seq = prot_file['Sequence'].tolist()\n",
    "\n",
    "prot_file_dict = {}\n",
    "\n",
    "for ix, pfpid in enumerate(prot_file_pid):\n",
    "    pfstr = pfpid + ':' + prot_file_seq[ix]\n",
    "    prot_file_dict[pfpid] = pfstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db665e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_file_cid = comp_file['Compound_ID'].tolist()\n",
    "comp_file_smiles = comp_file['smiles'].tolist()\n",
    "\n",
    "comp_file_dict = {}\n",
    "\n",
    "for icx, cfcid in enumerate(comp_file_cid):\n",
    "    cfstr = cfcid + ':' + comp_file_smiles[icx]\n",
    "    comp_file_dict[cfcid] = cfstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51fa73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_file_pid = act_file['Protein_ID'].tolist()\n",
    "act_file_cid = act_file['Compound_ID'].tolist()\n",
    "act_file_label = act_file['Label'].tolist()\n",
    "\n",
    "act_file_label = [int(x) for x in act_file_label]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb137f",
   "metadata": {},
   "source": [
    "## prediction for CYP450 test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9309f710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 21:24:24.219062: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-29 21:24:24.219091: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-29 21:24:24.219501: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "graph = tf.compat.v1.get_default_graph()\n",
    "ld_model = tf.keras.models.load_model('../CNN_results_split_final/Final_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f4618cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "score_ls = []\n",
    "pred_label_ls = []\n",
    "comp_label_ls = []\n",
    "see_ls = []\n",
    "\n",
    "\n",
    "TP_ls = []\n",
    "TN_ls = []\n",
    "FP_ls = []\n",
    "FN_ls = []\n",
    "\n",
    "for act_idx, act_cid in enumerate(act_file_cid):\n",
    "    \n",
    "    act_pid= act_file_pid[act_idx]\n",
    "    act_label = act_file_label[act_idx]\n",
    "    \n",
    "    cstr = comp_file_dict[act_cid]\n",
    "    pstr = prot_file_dict[act_pid]\n",
    "    \n",
    "    prot_feature, prot_id = prot_feature_gen_from_str_input(pstr)\n",
    "    comp_feature, comp_id = mol_feature_gen_from_str_input(cstr)\n",
    "    \n",
    "\n",
    "    act_dataframe = act_df_gen_mol_feature(comp_id, prot_id)\n",
    "    compound_feature = compound_feature_gen_df_input(act_dataframe, comp_feature)\n",
    "    y = ld_model.predict([compound_feature, prot_feature])\n",
    "    score_ls.append(y)\n",
    "    \n",
    "    if y<0.5:\n",
    "        pred_label = 0\n",
    "    else:\n",
    "        pred_label = 1\n",
    "        \n",
    "    if act_label == 1 and pred_label == 1:\n",
    "        TP_ls.append([act_pid, act_cid, act_label, pred_label])\n",
    "    elif act_label == 1 and pred_label == 0:\n",
    "        FN_ls.append([act_pid, act_cid, act_label, pred_label])\n",
    "    elif act_label == 0 and pred_label == 1:\n",
    "        FP_ls.append([act_pid, act_cid, act_label, pred_label])\n",
    "    elif act_label == 0 and pred_label == 0:\n",
    "        TN_ls.append([act_pid, act_cid, act_label, pred_label])\n",
    "        \n",
    "        \n",
    "    pred_label_ls.append(pred_label)\n",
    "    comp_label_ls.append([act_label, pred_label])\n",
    "    see_ls.append([act_pid, act_cid,y[0][0], act_label, pred_label])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c746ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2b71d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Q9NYL5', 'C13550', 1, 1],\n",
       " ['Q64441', 'C01561', 1, 1],\n",
       " ['Q64441', 'C05443', 1, 1],\n",
       " ['P10632', 'C00219', 1, 1],\n",
       " ['P10632', 'C06429', 1, 1],\n",
       " ['P10632', 'C00951', 1, 1],\n",
       " ['P51581', 'C06429', 1, 1],\n",
       " ['P28649', 'C00535', 1, 1],\n",
       " ['P28649', 'C05290', 1, 1],\n",
       " ['P28649', 'C00468', 1, 1],\n",
       " ['P00185', 'C00468', 1, 1],\n",
       " ['P00185', 'C00951', 1, 1]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "680a67f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['P10632', 'C01438', 0, 0],\n",
       " ['P10632', 'C00109', 0, 0],\n",
       " ['P10632', 'C00022', 0, 0],\n",
       " ['P10632', 'C06423', 0, 0],\n",
       " ['P10632', 'C00163', 0, 0],\n",
       " ['P10632', 'C00246', 0, 0],\n",
       " ['P51581', 'C01438', 0, 0],\n",
       " ['P51581', 'C00109', 0, 0],\n",
       " ['P51581', 'C06423', 0, 0],\n",
       " ['P51581', 'C00163', 0, 0],\n",
       " ['P51581', 'C00246', 0, 0],\n",
       " ['P00185', 'C01438', 0, 0],\n",
       " ['P00185', 'C00109', 0, 0],\n",
       " ['P00185', 'C00022', 0, 0],\n",
       " ['P00185', 'C06423', 0, 0],\n",
       " ['P00185', 'C00163', 0, 0],\n",
       " ['P00185', 'C00246', 0, 0],\n",
       " ['P00185', 'C00803', 0, 0],\n",
       " ['P00185', 'C01585', 0, 0]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33425127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['P51581', 'C00022', 0, 1]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc7b67b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Q64441', 'C01673', 1, 0],\n",
       " ['P10632', 'C00777', 1, 0],\n",
       " ['P28649', 'C00280', 1, 0],\n",
       " ['P28649', 'C05297', 1, 0]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FN_ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd02ad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive recovery:  0.75\n",
      "negative recovery:  0.95\n"
     ]
    }
   ],
   "source": [
    "positive_recovery = len(TP_ls)/(len(TP_ls) + len(FN_ls))\n",
    "negative_recovery = len(TN_ls)/(len(FP_ls) + len(TN_ls))\n",
    "\n",
    "print('Positive recovery: ', positive_recovery)\n",
    "print('negative recovery: ', negative_recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98217535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TP_ls) + len(FN_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a8f0343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Q9NYL5', 'C13550', 0.5132372, 1, 1],\n",
       " ['Q64441', 'C01673', 0.38006923, 1, 0],\n",
       " ['Q64441', 'C01561', 0.65167063, 1, 1],\n",
       " ['Q64441', 'C05443', 0.587643, 1, 1],\n",
       " ['P10632', 'C00219', 0.9721749, 1, 1],\n",
       " ['P10632', 'C06429', 0.8000854, 1, 1],\n",
       " ['P10632', 'C00777', 0.22985458, 1, 0],\n",
       " ['P10632', 'C00951', 0.9876478, 1, 1],\n",
       " ['P10632', 'C01438', 0.34986204, 0, 0],\n",
       " ['P10632', 'C00109', 0.0030233562, 0, 0],\n",
       " ['P10632', 'C00022', 0.17397922, 0, 0],\n",
       " ['P10632', 'C06423', 0.09950569, 0, 0],\n",
       " ['P10632', 'C00163', 0.0067325532, 0, 0],\n",
       " ['P10632', 'C00246', 0.011217833, 0, 0],\n",
       " ['P51581', 'C06429', 0.5959733, 1, 1],\n",
       " ['P51581', 'C01438', 0.3993878, 0, 0],\n",
       " ['P51581', 'C00109', 0.107837886, 0, 0],\n",
       " ['P51581', 'C00022', 0.64545226, 0, 1],\n",
       " ['P51581', 'C06423', 0.36598843, 0, 0],\n",
       " ['P51581', 'C00163', 0.13346031, 0, 0],\n",
       " ['P51581', 'C00246', 0.1963638, 0, 0],\n",
       " ['P28649', 'C00535', 0.72955155, 1, 1],\n",
       " ['P28649', 'C05290', 0.6119687, 1, 1],\n",
       " ['P28649', 'C00468', 0.9385452, 1, 1],\n",
       " ['P28649', 'C00280', 0.41291073, 1, 0],\n",
       " ['P28649', 'C05297', 0.16852686, 1, 0],\n",
       " ['P00185', 'C00468', 0.69187903, 1, 1],\n",
       " ['P00185', 'C00951', 0.8572688, 1, 1],\n",
       " ['P00185', 'C01438', 0.09076816, 0, 0],\n",
       " ['P00185', 'C00109', 0.014343917, 0, 0],\n",
       " ['P00185', 'C00022', 0.1269489, 0, 0],\n",
       " ['P00185', 'C06423', 0.09883472, 0, 0],\n",
       " ['P00185', 'C00163', 0.007890195, 0, 0],\n",
       " ['P00185', 'C00246', 0.022479355, 0, 0],\n",
       " ['P00185', 'C00803', 0.20315927, 0, 0],\n",
       " ['P00185', 'C01585', 0.21922407, 0, 0]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69e617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
